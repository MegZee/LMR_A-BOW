{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metonymy Resolution BOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OU2482gX-y7jtBY1FlTTb15jR9himGZA",
      "authorship_tag": "ABX9TyNAEGb3TZ4tXJIeFQFEYO07"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The beginning of the training phase"
      ],
      "metadata": {
        "id": "RvJQmsbM7tw4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBqTJuZ0BC_f",
        "outputId": "f5c04725-9ac2-4555-82f6-2708c3b68024"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdWr-xykDXiq",
        "outputId": "8ffd891f-0dc6-4fda-e0e5-2aab8a73653a"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZqgNjtgDXnh"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, LSTM \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Embedding,Activation, Dropout\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQTXyXgBDXlR"
      },
      "source": [
        "# #---------SEMEVAL\n",
        "\n",
        "# import pickle \n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Semeval/bow/all_words_semeval_train_metonymic_10.pkl', mode='rb') as f:\n",
        "#   metList = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Semeval/bow/all_words_semeval_train_literal_10.pkl', mode='rb') as f:\n",
        "#   litList = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Semeval/bow/all_words_semeval_test_metonymic_10.pkl', mode='rb') as f:\n",
        "#   metList_test = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Semeval/bow/all_words_semeval_test_literal_10.pkl', mode='rb') as f:\n",
        "#   litList_test = pickle.load(f)\n",
        "#   f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEEPdli5RDmr"
      },
      "source": [
        "# #-----------CONLL\n",
        "\n",
        "# import pickle \n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Conll/bow/all_words_conll_train_metonymic_10.pkl', mode='rb') as f:\n",
        "#   metList = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Conll/bow/all_words_conll_train_literal_10.pkl', mode='rb') as f:\n",
        "#   litList = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Conll/bow/all_words_conll_test_metonymic_10.pkl', mode='rb') as f:\n",
        "#   metList_test = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/Conll/bow/all_words_conll_test_literal_10.pkl', mode='rb') as f:\n",
        "#   litList_test = pickle.load(f)\n",
        "#   f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUQXdzKnDnv_"
      },
      "source": [
        "#---------WIMCOR\n",
        "\n",
        "# import pickle \n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/wimcor/bow/all_words_wimcor_train_metonymic_10.pkl', mode='rb') as f:\n",
        "#   metList = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/wimcor/bow/all_words_wimcor_train_literal_10.pkl', mode='rb') as f:\n",
        "#   litList = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/wimcor/bow/all_words_wimcor_test_metonymic_10.pkl', mode='rb') as f:\n",
        "#   metList_test = pickle.load(f)\n",
        "#   f.close()\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/wimcor/bow/all_words_wimcor_test_literal_10.pkl', mode='rb') as f:\n",
        "#   litList_test = pickle.load(f)\n",
        "#   f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbm4cV0jA39Y"
      },
      "source": [
        "# #--------RELOCAR\n",
        "\n",
        "import pickle \n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/ReLocaR/bow/all_words_relocar_train_metonymic_10.pkl', mode='rb') as f:\n",
        "  metList = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/ReLocaR/bow/all_words_relocar_train_literal_10.pkl', mode='rb') as f:\n",
        "  litList = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/ReLocaR/bow/all_words_relocar_test_metonymic_10.pkl', mode='rb') as f:\n",
        "  metList_test = pickle.load(f)\n",
        "  f.close()\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/ReLocaR/bow/all_words_relocar_test_literal_10.pkl', mode='rb') as f:\n",
        "  litList_test = pickle.load(f)\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnbNoQCrUBr6",
        "outputId": "2e6dab21-5fab-413e-9efc-e897121a8342"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "MetTrainLabel = [1 for i in range(len(metList))]\n",
        "MetTestLabel = [1 for i in range(len(metList_test))]\n",
        "litTrainLabel = [0 for i in range(len(litList))]\n",
        "litTestLabel = [0 for i in range(len(litList_test))]\n",
        "\n",
        "dict1 = {'Sentence':metList, 'Label':MetTrainLabel}\n",
        "dict2 = {'Sentence':litList, 'Label':litTrainLabel}\n",
        "\n",
        "df1 = pd.DataFrame(dict1)\n",
        "df2 = pd.DataFrame(dict2)\n",
        "frame = [df1, df2]\n",
        "df_train = pd.concat(frame)\n",
        "\n",
        "dictA = {'Sentence':metList_test, 'Label':MetTestLabel}\n",
        "dictB = {'Sentence':litList_test, 'Label':litTestLabel}\n",
        "\n",
        "dfa = pd.DataFrame(dictA)\n",
        "dfb = pd.DataFrame(dictB)\n",
        "frame1 = [dfa, dfb]\n",
        "df_test = pd.concat(frame1)\n",
        "print(df_train,'\\n-------',df_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Sentence  Label\n",
            "0            [from, to, played, on, team, the, for, one]      1\n",
            "1      [with, many, for, to, some, such, as, the, by,...      1\n",
            "2                           [the, on, by, now, with, to]      1\n",
            "3      [the, because, declared, by, from, as, for, an...      1\n",
            "4      [the, many, from, other, not, two, would, have...      1\n",
            "...                                                  ...    ...\n",
            "48481  [on, of, from, near, in, northern, the, high, ...      0\n",
            "48482                 [in, united, kingdom, of, britain]      0\n",
            "48483  [in, the, of, from, member, south, went, to, a...      0\n",
            "48484                 [village, in, the, of, some, east]      0\n",
            "48485                  [village, of, district, province]      0\n",
            "\n",
            "[64519 rows x 2 columns] \n",
            "-------                                                 Sentence  Label\n",
            "0      [over, go, on, to, domestic, international, many]      1\n",
            "1      [after, first, now, one, the, secretary, to, f...      1\n",
            "2      [during, the, over, from, on, war, united, sta...      1\n",
            "3      [on, the, first, test, football, tests, out, t...      1\n",
            "4                        [to, the, for, from, after, as]      1\n",
            "...                                                  ...    ...\n",
            "29271                                      [in, the, of]      0\n",
            "29272  [there, from, to, include, as, well, of, the, ...      0\n",
            "29273  [the, of, to, which, again, on, during, next, ...      0\n",
            "29274  [in, again, the, of, to, peace, between, durin...      0\n",
            "29275              [to, the, of, on, then, as, in, king]      0\n",
            "\n",
            "[39160 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvUT6CjPUBul",
        "outputId": "1369d58e-ef1d-43c8-f26a-3d6efb3e67e0"
      },
      "source": [
        "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
        "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
        "print(df_train,'\\n-------',df_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Sentence  Label\n",
            "0      [in, but, to, have, districts, the, of, out, i...      0\n",
            "1                                             [east, in]      0\n",
            "2      [in, the, of, to, since, when, for, subsidiary...      0\n",
            "3               [on, in, the, to, there, from, included]      0\n",
            "4      [the, city, least, area, of, on, ran, from, in...      0\n",
            "...                                                  ...    ...\n",
            "64514                 [in, on, the, same, year, for, to]      0\n",
            "64515  [the, government, for, from, four, as, provide...      1\n",
            "64516                           [have, on, the, are, by]      1\n",
            "64517  [the, representing, on, against, for, to, as, ...      1\n",
            "64518                  [the, in, province, to, city, of]      0\n",
            "\n",
            "[64519 rows x 2 columns] \n",
            "-------                                                 Sentence  Label\n",
            "0      [market, town, on, the, between, in, district,...      0\n",
            "1      [during, the, part, of, province, from, area, ...      0\n",
            "2      [there, still, some, to, the, new, of, as, set...      0\n",
            "3      [the, new, year, for, during, following, to, 2...      1\n",
            "4      [in, on, to, where, new, high, state, the, fro...      0\n",
            "...                                                  ...    ...\n",
            "39155                               [for, with, the, by]      1\n",
            "39156     [county, in, met, the, entire, of, west, east]      0\n",
            "39157                   [the, as, from, to, for, on, us]      1\n",
            "39158  [the, on, officers, there, as, since, into, to...      0\n",
            "39159  [in, city, of, the, from, state, where, to, be...      0\n",
            "\n",
            "[39160 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQD0X8luUBxC",
        "outputId": "370b53fc-dc9c-45bc-9938-75ce1cd0b299"
      },
      "source": [
        "frame2 = [df_train, df_test]\n",
        "dfAll = pd.concat(frame2)\n",
        "\n",
        "# dfAll = dfAll.sample(frac=1).reset_index(drop=True)\n",
        "# df_train, df_test = train_test_split(dfAll, test_size=0.2)\n",
        "\n",
        "textAll = dfAll['Sentence'].tolist()\n",
        "textTrain = df_train['Sentence'].tolist()\n",
        "textTest = df_test['Sentence'].tolist()\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(textAll)\n",
        "len(df_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39160"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmAP02EuUBzW",
        "outputId": "09af9840-2433-4846-c2e0-dbddad20a971"
      },
      "source": [
        "vocab_size  = len(token.word_index)+1\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7993"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck_eXfKsUr8D",
        "outputId": "87bc1146-af3a-4931-d05a-e40aa1ff16ee"
      },
      "source": [
        "encoded_textTrain = token.texts_to_sequences(textTrain)\n",
        "encoded_textTest = token.texts_to_sequences(textTest)\n",
        "print(len(encoded_textTrain), len(encoded_textTest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64519 39160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgLQIPOtUr-z",
        "outputId": "adc096b3-1051-42eb-bdf5-5878ee0825e4"
      },
      "source": [
        "max_length = 24\n",
        "X = pad_sequences(encoded_textTrain, maxlen=max_length, padding='post')\n",
        "y = pad_sequences(encoded_textTest, maxlen=max_length, padding='post')\n",
        "# X = pad_sequences(encoded_textTrain, maxlen=max_length+2, padding='pre')\n",
        "# y = pad_sequences(encoded_textTest, maxlen=max_length+2, padding='pre')\n",
        "print(X,'\\n', X.shape)\n",
        "print(y,'\\n', y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2  12   3 ...   0   0   0]\n",
            " [ 39   2   0 ...   0   0   0]\n",
            " [  2   1   4 ...   0   0   0]\n",
            " ...\n",
            " [ 17   6   1 ...   0   0   0]\n",
            " [  1 374   6 ...   0   0   0]\n",
            " [  1   2 135 ...   0   0   0]] \n",
            " (64519, 24)\n",
            "[[179  37   6 ...   0   0   0]\n",
            " [ 13   1  34 ...   0   0   0]\n",
            " [ 30  75  31 ...  60  96 252]\n",
            " ...\n",
            " [  1   5   8 ...   0   0   0]\n",
            " [  1   6 280 ...   0   0   0]\n",
            " [  2  24   4 ...   0   0   0]] \n",
            " (39160, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRWhXjC2UsCx",
        "outputId": "7a65b641-aa6f-42e5-d4c3-57dda7704d70"
      },
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "\n",
        "glove_vectors = dict()\n",
        "\n",
        "\n",
        "# file = open('glove.twitter.27B.200d.txt', encoding='utf-8')\n",
        "file = open('/content/drive/MyDrive/Colab Notebooks/GloVe 50D/glove.6B.50d.txt', encoding='utf-8')\n",
        "\n",
        "for line in file:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    #storing the word in the variable\n",
        "    vectors = np.asarray(values[1: ])\n",
        "    #storing the vector representation of the respective word in the dictionary\n",
        "    glove_vectors[word] = vectors\n",
        "file.close()\n",
        "\n",
        "word_vector_matrix = np.zeros((vocab_size, 50))\n",
        "\n",
        "for word, index in token.word_index.items():\n",
        "    vector = glove_vectors.get(word)\n",
        "    if vector is not None:\n",
        "        word_vector_matrix[index] = vector\n",
        "word_vector_matrix.shape    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.95 s, sys: 499 ms, total: 5.45 s\n",
            "Wall time: 5.39 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xLdCfy_U2mk",
        "outputId": "e681c649-eae4-4b13-e4da-1d40d97d7f84"
      },
      "source": [
        "X_train = X\n",
        "X_test = y\n",
        "\n",
        "y_train = df_train['Label']\n",
        "y_test = df_test['Label']\n",
        "y_train = y_train.values.reshape(-1,1)\n",
        "y_test = y_test.values.reshape(-1,1)\n",
        "\n",
        "print(X_train, ' ',X_train.shape,'\\n')\n",
        "print(X_test, ' ',X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2  12   3 ...   0   0   0]\n",
            " [ 39   2   0 ...   0   0   0]\n",
            " [  2   1   4 ...   0   0   0]\n",
            " ...\n",
            " [ 17   6   1 ...   0   0   0]\n",
            " [  1 374   6 ...   0   0   0]\n",
            " [  1   2 135 ...   0   0   0]]   (64519, 24) \n",
            "\n",
            "[[179  37   6 ...   0   0   0]\n",
            " [ 13   1  34 ...   0   0   0]\n",
            " [ 30  75  31 ...  60  96 252]\n",
            " ...\n",
            " [  1   5   8 ...   0   0   0]\n",
            " [  1   6 280 ...   0   0   0]\n",
            " [  2  24   4 ...   0   0   0]]   (39160, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, a_test, y_train, b_test = train_test_split(X_train, y_train, \n",
        "                                                    train_size=0.67, \n",
        "                                                    random_state=42)\n",
        "\n",
        "print(X_train, ' ',X_train.shape,'\\n')\n",
        "print(a_test, ' ',b_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szARHDHGpDUa",
        "outputId": "27d920c5-36b8-4071-e96d-45a017a47e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  1   8   7 ...   0   0   0]\n",
            " [  3  31   1 ...   0   0   0]\n",
            " [ 65  43  17 ...   0   0   0]\n",
            " ...\n",
            " [ 79   3   1 ...   0   0   0]\n",
            " [  1  52  11 ...   0   0   0]\n",
            " [ 21  64 316 ...   3   0   0]]   (43227, 24) \n",
            "\n",
            "[[ 17   2   0 ...   0   0   0]\n",
            " [  4   5   2 ...   0   0   0]\n",
            " [  2   7   1 ...   0   0   0]\n",
            " ...\n",
            " [  1  68   4 ...   0   0   0]\n",
            " [ 89   2   1 ...   0   0   0]\n",
            " [127   6   1 ...   0   0   0]]   (21292, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp7P0RxIU2pV",
        "outputId": "9b91a443-c3f1-4341-c881-14a2bfb17517"
      },
      "source": [
        "vec_size = 50\n",
        "\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1s = []\n",
        "\n",
        "for i in range(1):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, vec_size, input_length=max_length,\n",
        "                      weights = [word_vector_matrix], trainable = False))\n",
        "  model.add(Conv1D(64, 12, activation = 'relu'))\n",
        "  model.add(MaxPooling1D(2))\n",
        "  # LSTM(100)\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer=Adam(learning_rate = 0.0001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  classifier = model.fit(X_train, y_train, epochs =60, validation_data = (a_test, b_test))\n",
        "\n",
        "\n",
        "  yhat_probs = model.predict(X_test, verbose=0)\n",
        "  yhat_classes = model.predict_classes(X_test, verbose=0)\n",
        "  yhat_probs = yhat_probs[:, 0]\n",
        "  yhat_classes = yhat_classes[:, 0]\n",
        "  \n",
        "  accuracy = accuracy_score(y_test, yhat_classes)\n",
        "  precision = precision_score(y_test, yhat_classes)\n",
        "  recall = recall_score(y_test, yhat_classes)\n",
        "  f1 = f1_score(y_test, yhat_classes)\n",
        "\n",
        "  accuracies.append(accuracy)\n",
        "  precisions.append(precision)\n",
        "  recalls.append(recall)\n",
        "  f1s.append(f1)\n",
        "\n",
        "print('Training is DONE...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1351/1351 [==============================] - 10s 6ms/step - loss: 0.3098 - accuracy: 0.8647 - val_loss: 0.1286 - val_accuracy: 0.9667\n",
            "Epoch 2/5\n",
            "1351/1351 [==============================] - 8s 6ms/step - loss: 0.1252 - accuracy: 0.9575 - val_loss: 0.0745 - val_accuracy: 0.9809\n",
            "Epoch 3/5\n",
            "1351/1351 [==============================] - 8s 6ms/step - loss: 0.0807 - accuracy: 0.9734 - val_loss: 0.0553 - val_accuracy: 0.9839\n",
            "Epoch 4/5\n",
            "1351/1351 [==============================] - 8s 6ms/step - loss: 0.0614 - accuracy: 0.9803 - val_loss: 0.0462 - val_accuracy: 0.9873\n",
            "Epoch 5/5\n",
            "1351/1351 [==============================] - 7s 5ms/step - loss: 0.0491 - accuracy: 0.9845 - val_loss: 0.0429 - val_accuracy: 0.9884\n",
            "Training is DONE...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import *\n",
        "# std_acc = []\n",
        "# for i in range(len(accuracies)):\n",
        "#   std_acc.append(i)\n",
        "avgAcc = mean(accuracies)\n",
        "print(\"The average is \", round(avgAcc,4))\n",
        "arr = np.array(accuracies)\n",
        "print('\\nstd is: ',np.std(arr))\n",
        "\n",
        "avgP =  mean(precisions)\n",
        "print(\"\\nThe precisions average is \", round(avgP,4))\n",
        "avgR = mean(recalls)\n",
        "print(\"\\nThe recalls average is \", round(avgR,4))\n",
        "avgF1 = mean(f1s)\n",
        "print(\"\\nThe f1s average is \", round(avgF1,4))\n",
        "\n",
        "matrix = confusion_matrix(y_test, yhat_classes)\n",
        "print('the matrix:\\n',matrix)"
      ],
      "metadata": {
        "id": "ckysJ83V651L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(classifier.history['loss'], label='train')\n",
        "plt.plot(classifier.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m6qW7J8m7Vn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing some Error Analysis"
      ],
      "metadata": {
        "id": "PQA-A_iK7Xch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "yhat = model.predict(X_test, verbose=0)\n",
        "\n",
        "yhat = np.where(yhat > 0.5, 1, 0)\n",
        "\n",
        "yhat = yhat.flatten()\n",
        "yhat = yhat.tolist()\n",
        "\n",
        "selection = []\n",
        "for i in range(len(yhat)):\n",
        "  if y_test[i] == yhat[i]:\n",
        "    selection.append(0)\n",
        "  else:\n",
        "    selection.append(1)\n",
        "\n",
        "selection.count(0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hapk8Li3RqV",
        "outputId": "2175e24e-8b6d-4655-84ef-b5504665a4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38728"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sl = pd.DataFrame(selection)\n",
        "sl.columns = ['pred']\n",
        "erroranalysis = pd.concat([sl,df_test],axis=1)\n",
        "erroranalysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "fjEhWIlUGQ6i",
        "outputId": "7ff5a577-2419-42f0-f7f6-7a9dd92b7579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       pred                                           Sentence  Label\n",
              "0         0  [market, town, on, the, between, in, district,...      0\n",
              "1         0  [during, the, part, of, province, from, area, ...      0\n",
              "2         0  [there, still, some, to, the, new, of, as, set...      0\n",
              "3         0  [the, new, year, for, during, following, to, 2...      1\n",
              "4         0  [in, on, to, where, new, high, state, the, fro...      0\n",
              "...     ...                                                ...    ...\n",
              "39155     0                               [for, with, the, by]      1\n",
              "39156     0     [county, in, met, the, entire, of, west, east]      0\n",
              "39157     0                   [the, as, from, to, for, on, us]      1\n",
              "39158     0  [the, on, officers, there, as, since, into, to...      0\n",
              "39159     0  [in, city, of, the, from, state, where, to, be...      0\n",
              "\n",
              "[39160 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-752af38f-28e6-48a1-b097-2aa98452ba5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[market, town, on, the, between, in, district,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[during, the, part, of, province, from, area, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[there, still, some, to, the, new, of, as, set...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[the, new, year, for, during, following, to, 2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[in, on, to, where, new, high, state, the, fro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39155</th>\n",
              "      <td>0</td>\n",
              "      <td>[for, with, the, by]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39156</th>\n",
              "      <td>0</td>\n",
              "      <td>[county, in, met, the, entire, of, west, east]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39157</th>\n",
              "      <td>0</td>\n",
              "      <td>[the, as, from, to, for, on, us]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39158</th>\n",
              "      <td>0</td>\n",
              "      <td>[the, on, officers, there, as, since, into, to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39159</th>\n",
              "      <td>0</td>\n",
              "      <td>[in, city, of, the, from, state, where, to, be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39160 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-752af38f-28e6-48a1-b097-2aa98452ba5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-752af38f-28e6-48a1-b097-2aa98452ba5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-752af38f-28e6-48a1-b097-2aa98452ba5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: total number of rows (39160) exceeds max_rows (20000). Limiting to first (20000) rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AC-8BAxGJGf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dYmRfCWCJGxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-SyQculVCm6"
      },
      "source": [
        "# _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "# _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "# print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}